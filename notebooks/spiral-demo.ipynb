{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import spiral.agents.default as default_agent\n",
    "import spiral.agents.utils as agent_utils\n",
    "from spiral.environments import fluid\n",
    "from spiral.environments import libmypaint\n",
    "\n",
    "\n",
    "nest = tf.contrib.framework.nest\n",
    "\n",
    "# Disable TensorFlow debug output.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample from the model\n",
    "\n",
    "This section demonstrates the most basic usage of the package, i.e., sampling from a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to libmypaint brushes.\n",
    "BRUSHES_BASEDIR = os.path.join(os.getcwd(), \"..\", \"third_party/mypaint-brushes-1.3.0\")\n",
    "BRUSHES_BASEDIR = os.path.abspath(BRUSHES_BASEDIR)\n",
    "# The path to a TF-Hub module.\n",
    "MODULE_PATH = \"https://tfhub.dev/deepmind/spiral/default-wgangp-celebahq64-gen-19steps/agent4/1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the environment\n",
    "\n",
    "First, we need to create the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_settings = dict(\n",
    "    episode_length=20,                 # Number of frames in each episode.\n",
    "    canvas_width=64,                   # The width of the canvas in pixels.\n",
    "    grid_width=32,                     # The width of the action grid.\n",
    "    brush_type=\"classic/dry_brush\",    # The type of the brush.\n",
    "    brush_sizes=[1, 2, 4, 8, 12, 24],  # The sizes of the brush to use.\n",
    "    use_color=True,                    # Color or black & white output?\n",
    "    use_pressure=True,                 # Use pressure parameter of the brush?\n",
    "    use_alpha=False,                   # Drop or keep the alpha channel of the canvas?\n",
    "    background=\"white\",                # Background could either be \"white\" or \"transparent\".\n",
    "    brushes_basedir=BRUSHES_BASEDIR,   # The location of libmypaint brushes.\n",
    ")\n",
    "env = libmypaint.LibMyPaint(**env_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the agent\n",
    "\n",
    "We provide a convenience function `get_module_wrappers` that returns two `python` functions implementing the agent.\n",
    "The first one, `initial_state`, is used to get the initial state of the agent (specifically, the state of the LSTM).\n",
    "The second, `step`, takes an observation from the environment and performs a single agent step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "initial_state, step = agent_utils.get_module_wrappers(MODULE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = initial_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following cell will return a sample from the model. You can execute it multiple times until you get the one that you like. In addition to showing the final state of the canvas we also record all the agent's actions (note `actions` variable) needed to reproduce it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_sample = np.random.normal(size=(10,)).astype(np.float32)\n",
    "\n",
    "time_step = env.reset()\n",
    "actions = []\n",
    "for t in range(19):\n",
    "    time_step.observation[\"noise_sample\"] = noise_sample\n",
    "    action, state = step(time_step.step_type, time_step.observation, state)\n",
    "    time_step = env.step(action)\n",
    "    actions.append(action)\n",
    "    \n",
    "plt.close(\"all\")\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(time_step.observation[\"canvas\"], interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulate the sample\n",
    "\n",
    "Let's now do something the obtained sample. Since we have the corresponding sequence of actions we can re-render the image in higher resolution. To that end, we will need to create one more environment with modified settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a high-resolution version of the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make the canvas 8x8 times bigger.\n",
    "SCALE_FACTOR = 8\n",
    "\n",
    "# Patch the environments setting for higher resolution.\n",
    "hires_env_settings = copy.deepcopy(env_settings)\n",
    "hires_env_settings[\"canvas_width\"] *= SCALE_FACTOR\n",
    "hires_env_settings[\"brush_sizes\"] = [\n",
    "    s * SCALE_FACTOR for s in hires_env_settings[\"brush_sizes\"]]\n",
    "\n",
    "env = libmypaint.LibMyPaint(**hires_env_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute pre-recorded actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "for t in range(19):\n",
    "    time_step = env.step(actions[t])\n",
    "    \n",
    "plt.close(\"all\")\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(time_step.observation[\"canvas\"], interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the thickness of the brush strokes\n",
    "\n",
    "In addition to changing the resolution of the images, let's in introduce some more subtle structural changes. We could, for example, change the thickness of all the strokes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_actions = copy.deepcopy(actions)\n",
    "for action in modified_actions:\n",
    "    action[\"size\"] = np.array(0, dtype=np.int32)\n",
    "    action[\"pressure\"] = np.array(2, dtype=np.int32)\n",
    "\n",
    "env.reset()\n",
    "for t in range(19):\n",
    "    time_step = env.step(modified_actions[t])\n",
    "    \n",
    "plt.close(\"all\")\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(time_step.observation[\"canvas\"], interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the brush type\n",
    "\n",
    "Finally, let's re-render the image above using a different brush type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch the environments setting for a different brush.\n",
    "pen_env_settings = copy.deepcopy(hires_env_settings)\n",
    "pen_env_settings[\"brush_type\"] = \"classic/pen\"\n",
    "\n",
    "env = libmypaint.LibMyPaint(**pen_env_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "for t in range(19):\n",
    "    time_step = env.step(modified_actions[t])\n",
    "    \n",
    "plt.close(\"all\")\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(time_step.observation[\"canvas\"], interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fluid Paint environment demonstration\n",
    "\n",
    "Fluid Paint environment works almost exactly like `libmypaint.LibMyPaint`. Below, we show how to obtain samples from the model trained in this environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the shaders.\n",
    "SHADERS_BASEDIR = os.path.join(os.getcwd(), \"..\", \"third_party/paint/shaders\")\n",
    "SHADERS_BASEDIR = os.path.abspath(SHADERS_BASEDIR)\n",
    "# The path to a TF-Hub module.\n",
    "MODULE_PATH = \"https://tfhub.dev/deepmind/spiral/default-fluid-gansn-celebahq64-gen-19steps/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_settings = dict(\n",
    "    episode_length=20,                               # Number of frames in each episode.\n",
    "    canvas_width=256,                                # The width of the canvas in pixels.\n",
    "    grid_width=32,                                   # The width of the action grid.\n",
    "    brush_sizes=[2.5, 5.0, 10.0, 20.0, 40.0, 80.0],  # The sizes of the brush to use.\n",
    "    shaders_basedir=SHADERS_BASEDIR,                 # The location of shaders.\n",
    ")\n",
    "env = fluid.FluidPaint(**env_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state, step = agent_utils.get_module_wrappers(MODULE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = initial_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_sample = np.random.normal(size=(10,)).astype(np.float32)\n",
    "\n",
    "time_step = env.reset()\n",
    "actions = []\n",
    "for t in range(19):\n",
    "    time_step.observation[\"noise_sample\"] = noise_sample\n",
    "    # The environment uses 256x256 canvas but the agent requires 64x64 input.\n",
    "    ratio = 64 / 256\n",
    "    time_step.observation[\"canvas\"] = ndimage.zoom(\n",
    "        time_step.observation[\"canvas\"], [ratio, ratio, 1], order=1)\n",
    "    action, state = step(time_step.step_type, time_step.observation, state)\n",
    "    time_step = env.step(action)\n",
    "    actions.append(action)\n",
    "    \n",
    "plt.close(\"all\")\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(time_step.observation[\"canvas\"], interpolation=\"nearest\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
